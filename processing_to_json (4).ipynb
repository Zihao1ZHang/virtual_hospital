{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e66273-eda7-4e54-8165-37914903bf2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:43.962813Z",
     "iopub.status.busy": "2024-09-19T02:43:43.962646Z",
     "iopub.status.idle": "2024-09-19T02:43:45.092309Z",
     "shell.execute_reply": "2024-09-19T02:43:45.091705Z",
     "shell.execute_reply.started": "2024-09-19T02:43:43.962791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28dcd49e-2475-4ca8-bd43-663208459e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:45.097193Z",
     "iopub.status.busy": "2024-09-19T02:43:45.096510Z",
     "iopub.status.idle": "2024-09-19T02:43:55.446878Z",
     "shell.execute_reply": "2024-09-19T02:43:55.444057Z",
     "shell.execute_reply.started": "2024-09-19T02:43:45.097160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'physician.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphysician.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zihao\\anaconda3\\envs\\VirtualHospital\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zihao\\anaconda3\\envs\\VirtualHospital\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\zihao\\anaconda3\\envs\\VirtualHospital\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zihao\\anaconda3\\envs\\VirtualHospital\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\zihao\\anaconda3\\envs\\VirtualHospital\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'physician.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"physician.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80612078-0bce-458c-a27c-293a87f57c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:55.453684Z",
     "iopub.status.busy": "2024-09-19T02:43:55.453195Z",
     "iopub.status.idle": "2024-09-19T02:43:55.479813Z",
     "shell.execute_reply": "2024-09-19T02:43:55.479317Z",
     "shell.execute_reply.started": "2024-09-19T02:43:55.453646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141624, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b98cb80-0b3a-48ee-9e29-92c94fedc5b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:55.481235Z",
     "iopub.status.busy": "2024-09-19T02:43:55.480990Z",
     "iopub.status.idle": "2024-09-19T02:43:55.511929Z",
     "shell.execute_reply": "2024-09-19T02:43:55.511458Z",
     "shell.execute_reply.started": "2024-09-19T02:43:55.481213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316237</td>\n",
       "      <td>16605</td>\n",
       "      <td>109285.0</td>\n",
       "      <td>2138-03-21</td>\n",
       "      <td>2138-03-21 15:02:00</td>\n",
       "      <td>2138-03-21 15:03:05</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n Continu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316238</td>\n",
       "      <td>29075</td>\n",
       "      <td>179159.0</td>\n",
       "      <td>2116-02-07</td>\n",
       "      <td>2116-02-07 15:37:00</td>\n",
       "      <td>2116-02-07 15:37:10</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   EGD d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316241</td>\n",
       "      <td>29075</td>\n",
       "      <td>179159.0</td>\n",
       "      <td>2116-02-07</td>\n",
       "      <td>2116-02-07 15:37:00</td>\n",
       "      <td>2116-02-07 16:05:26</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 Hour Events:\\n   EGD demonstrated no eviden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316242</td>\n",
       "      <td>29075</td>\n",
       "      <td>179159.0</td>\n",
       "      <td>2116-02-07</td>\n",
       "      <td>2116-02-07 15:37:00</td>\n",
       "      <td>2116-02-07 16:08:06</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 Hour Events:\\n   EGD demonstrated no eviden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316243</td>\n",
       "      <td>31608</td>\n",
       "      <td>152365.0</td>\n",
       "      <td>2133-01-16</td>\n",
       "      <td>2133-01-16 16:12:00</td>\n",
       "      <td>2133-01-16 16:12:47</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint:\\n   24 Hour Events:\\n   Recei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "0  316237       16605  109285.0  2138-03-21  2138-03-21 15:02:00   \n",
       "1  316238       29075  179159.0  2116-02-07  2116-02-07 15:37:00   \n",
       "2  316241       29075  179159.0  2116-02-07  2116-02-07 15:37:00   \n",
       "3  316242       29075  179159.0  2116-02-07  2116-02-07 15:37:00   \n",
       "4  316243       31608  152365.0  2133-01-16  2133-01-16 16:12:00   \n",
       "\n",
       "             STORETIME    CATEGORY                       DESCRIPTION     CGID  \\\n",
       "0  2138-03-21 15:03:05  Physician   Physician Resident Progress Note  21203.0   \n",
       "1  2116-02-07 15:37:10  Physician   Physician Resident Progress Note  21203.0   \n",
       "2  2116-02-07 16:05:26  Physician   Physician Resident Progress Note  21203.0   \n",
       "3  2116-02-07 16:08:06  Physician   Physician Resident Progress Note  21203.0   \n",
       "4  2133-01-16 16:12:47  Physician   Physician Resident Progress Note  21203.0   \n",
       "\n",
       "   ISERROR                                               TEXT  \n",
       "0      NaN  Chief Complaint:\\n   24 Hour Events:\\n Continu...  \n",
       "1      NaN  Chief Complaint:\\n   24 Hour Events:\\n   EGD d...  \n",
       "2      NaN  24 Hour Events:\\n   EGD demonstrated no eviden...  \n",
       "3      NaN  24 Hour Events:\\n   EGD demonstrated no eviden...  \n",
       "4      NaN  Chief Complaint:\\n   24 Hour Events:\\n   Recei...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f9d374-5f12-4c9d-bd6c-6cb408f4c8bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:55.513029Z",
     "iopub.status.busy": "2024-09-19T02:43:55.512843Z",
     "iopub.status.idle": "2024-09-19T02:43:55.528000Z",
     "shell.execute_reply": "2024-09-19T02:43:55.527507Z",
     "shell.execute_reply.started": "2024-09-19T02:43:55.513012Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99383    481\n",
       "55672    464\n",
       "30202    463\n",
       "31942    365\n",
       "27427    363\n",
       "        ... \n",
       "61427      1\n",
       "77026      1\n",
       "67648      1\n",
       "93996      1\n",
       "72968      1\n",
       "Name: SUBJECT_ID, Length: 7623, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SUBJECT_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82443626-d250-42ed-8c20-d7e00056516b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af7baed6-edbd-49c8-acdb-bb15b4edcc8f",
   "metadata": {},
   "source": [
    "这里后面以单个subject_id测试了一下各类note的分布情况，以及包含soap的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0f61c5-4b8c-4597-91e8-e0ecaf8c5bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:43:55.529146Z",
     "iopub.status.busy": "2024-09-19T02:43:55.528884Z",
     "iopub.status.idle": "2024-09-19T02:43:55.539949Z",
     "shell.execute_reply": "2024-09-19T02:43:55.539149Z",
     "shell.execute_reply.started": "2024-09-19T02:43:55.529125Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Physician Resident Progress Note                      332\n",
       "Physician Attending Progress Note                     101\n",
       "Physician Resident/Attending Progress Note - MICU      27\n",
       "Physician Resident Admission Note                      10\n",
       "ICU Attending Note                                      4\n",
       "MICU Attending Admission Note                           1\n",
       "Attending progress note                                 1\n",
       "ICU Attending  Note                                     1\n",
       "Attending Note                                          1\n",
       "ICU Event Note                                          1\n",
       "Attending  Note                                         1\n",
       "Physician Resident/Attending Admission Note - MICU      1\n",
       "Name: DESCRIPTION, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df[df['SUBJECT_ID']==99383]\n",
    "df_1['DESCRIPTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42f1529-59a0-4e1e-bce8-49c4c266fee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:44:03.982203Z",
     "iopub.status.busy": "2024-09-19T02:44:03.981195Z",
     "iopub.status.idle": "2024-09-19T02:44:04.015958Z",
     "shell.execute_reply": "2024-09-19T02:44:04.014462Z",
     "shell.execute_reply.started": "2024-09-19T02:44:03.982172Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121666</th>\n",
       "      <td>692782</td>\n",
       "      <td>99383</td>\n",
       "      <td>181682.0</td>\n",
       "      <td>2131-08-22</td>\n",
       "      <td>2131-08-22 09:20:00</td>\n",
       "      <td>2131-08-22 15:31:12</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Attending Progress Note</td>\n",
       "      <td>20401.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint: leg hematoma\\n   I saw and ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121626</th>\n",
       "      <td>692754</td>\n",
       "      <td>99383</td>\n",
       "      <td>181682.0</td>\n",
       "      <td>2131-08-22</td>\n",
       "      <td>2131-08-22 09:20:00</td>\n",
       "      <td>2131-08-22 09:20:13</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Attending Progress Note</td>\n",
       "      <td>21242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint: leg hematoma\\n   I saw and ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121687</th>\n",
       "      <td>692752</td>\n",
       "      <td>99383</td>\n",
       "      <td>181682.0</td>\n",
       "      <td>2131-08-22</td>\n",
       "      <td>2131-08-22 07:14:00</td>\n",
       "      <td>2131-08-22 09:07:25</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>18019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint: Right thigh hematoma\\n   24 H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121678</th>\n",
       "      <td>692740</td>\n",
       "      <td>99383</td>\n",
       "      <td>181682.0</td>\n",
       "      <td>2131-08-22</td>\n",
       "      <td>2131-08-22 07:14:00</td>\n",
       "      <td>2131-08-22 07:27:55</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>16045.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint: Right thigh hematoma\\n   24 H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121676</th>\n",
       "      <td>692738</td>\n",
       "      <td>99383</td>\n",
       "      <td>181682.0</td>\n",
       "      <td>2131-08-22</td>\n",
       "      <td>2131-08-22 07:14:00</td>\n",
       "      <td>2131-08-22 07:16:39</td>\n",
       "      <td>Physician</td>\n",
       "      <td>Physician Resident Progress Note</td>\n",
       "      <td>16045.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chief Complaint: Right thigh hematoma\\n   24 H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "121666  692782       99383  181682.0  2131-08-22  2131-08-22 09:20:00   \n",
       "121626  692754       99383  181682.0  2131-08-22  2131-08-22 09:20:00   \n",
       "121687  692752       99383  181682.0  2131-08-22  2131-08-22 07:14:00   \n",
       "121678  692740       99383  181682.0  2131-08-22  2131-08-22 07:14:00   \n",
       "121676  692738       99383  181682.0  2131-08-22  2131-08-22 07:14:00   \n",
       "\n",
       "                  STORETIME    CATEGORY                        DESCRIPTION  \\\n",
       "121666  2131-08-22 15:31:12  Physician   Physician Attending Progress Note   \n",
       "121626  2131-08-22 09:20:13  Physician   Physician Attending Progress Note   \n",
       "121687  2131-08-22 09:07:25  Physician    Physician Resident Progress Note   \n",
       "121678  2131-08-22 07:27:55  Physician    Physician Resident Progress Note   \n",
       "121676  2131-08-22 07:16:39  Physician    Physician Resident Progress Note   \n",
       "\n",
       "           CGID  ISERROR                                               TEXT  \n",
       "121666  20401.0      NaN  Chief Complaint: leg hematoma\\n   I saw and ex...  \n",
       "121626  21242.0      NaN  Chief Complaint: leg hematoma\\n   I saw and ex...  \n",
       "121687  18019.0      NaN  Chief Complaint: Right thigh hematoma\\n   24 H...  \n",
       "121678  16045.0      NaN  Chief Complaint: Right thigh hematoma\\n   24 H...  \n",
       "121676  16045.0      NaN  Chief Complaint: Right thigh hematoma\\n   24 H...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df_1 = df_1.sort_values(by='ROW_ID', ascending=False)\n",
    "sorted_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159e5c30-4ead-4c3a-8eba-3cc30b33b4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:16.169050Z",
     "iopub.status.busy": "2024-09-19T02:46:16.168133Z",
     "iopub.status.idle": "2024-09-19T02:46:16.184803Z",
     "shell.execute_reply": "2024-09-19T02:46:16.183738Z",
     "shell.execute_reply.started": "2024-09-19T02:46:16.168992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m\n\u001b[0;32m     18\u001b[0m notes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysician Resident Progress Note\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysician Attending Progress Note\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysician Resident/Attending Progress Note - MICU\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttending  Note\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPhysician Resident/Attending Admission Note - MICU\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m note \u001b[38;5;129;01min\u001b[39;00m notes:\n\u001b[1;32m---> 31\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mdf_1\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mnote, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEXT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(note)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m contains_subjective(text):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_1' is not defined"
     ]
    }
   ],
   "source": [
    "def contains_subjective(text):\n",
    "    subjective_keywords = [\"reports\", \"complains\", \"symptoms\", \"history of\"]\n",
    "    return any(keyword in text.lower() for keyword in subjective_keywords)\n",
    "\n",
    "def contains_objective(text):\n",
    "    objective_keywords = [\"vital signs\", \"physical examination\", \"labs\", \"imaging\", \"findings\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_assessment(text):\n",
    "    objective_keywords = [\"assessment\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_plan(text):\n",
    "    objective_keywords = [\"plan\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "# test\n",
    "notes = ['Physician Resident Progress Note',\n",
    "         'Physician Attending Progress Note',\n",
    "         'Physician Resident/Attending Progress Note - MICU',\n",
    "         'Physician Resident Admission Note',\n",
    "         'ICU Attending Note',\n",
    "         'MICU Attending Admission Note',\n",
    "         'Attending progress note',\n",
    "         'ICU Attending  Note',\n",
    "         'Attending Note',\n",
    "         'ICU Event Note',\n",
    "         'Attending  Note',\n",
    "         'Physician Resident/Attending Admission Note - MICU']\n",
    "for note in notes:\n",
    "    text = df_1.loc[df_1['DESCRIPTION']==note, 'TEXT'].values[0]\n",
    "    print(note)\n",
    "    if contains_subjective(text):\n",
    "        print(\"This note contains subjective information.\")\n",
    "    if contains_objective(text):\n",
    "        print(\"This note contains objective information.\")\n",
    "    if contains_assessment(text):\n",
    "        print(\"This note contains assessment.\")\n",
    "    if contains_plan(text):\n",
    "        print(\"This note contains plan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4283262-0334-444f-8fe0-928cc1cb68a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7a15cee-21f6-4b17-9cd5-539110135176",
   "metadata": {},
   "source": [
    "上面是test，下面是extract and then split assessment and plan，然后存储为json的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51351aa8-9390-41f3-9493-726717ad0f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:21.762448Z",
     "iopub.status.busy": "2024-09-19T02:46:21.761697Z",
     "iopub.status.idle": "2024-09-19T02:46:21.767336Z",
     "shell.execute_reply": "2024-09-19T02:46:21.766527Z",
     "shell.execute_reply.started": "2024-09-19T02:46:21.762413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "537be0b9-ebf5-42ff-acd8-4c63247d95e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:23.609097Z",
     "iopub.status.busy": "2024-09-19T02:46:23.608227Z",
     "iopub.status.idle": "2024-09-19T02:46:32.758366Z",
     "shell.execute_reply": "2024-09-19T02:46:32.754344Z",
     "shell.execute_reply.started": "2024-09-19T02:46:23.609060Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"physician.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b914e504-561c-4edf-8eb4-544331ddc7f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:32.764994Z",
     "iopub.status.busy": "2024-09-19T02:46:32.763990Z",
     "iopub.status.idle": "2024-09-19T02:46:32.778145Z",
     "shell.execute_reply": "2024-09-19T02:46:32.776739Z",
     "shell.execute_reply.started": "2024-09-19T02:46:32.764954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_subjective(text):\n",
    "    subjective_keywords = [\"reports\", \"complains\", \"symptoms\", \"history of\"]\n",
    "    return any(keyword in text.lower() for keyword in subjective_keywords)\n",
    "\n",
    "def contains_objective(text):\n",
    "    objective_keywords = [\"vital signs\", \"physical examination\", \"labs\", \"imaging\", \"findings\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_assessment(text):\n",
    "    objective_keywords = [\"assessment\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_plan(text):\n",
    "    objective_keywords = [\"plan\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def check_condition(text):\n",
    "    if contains_subjective(text) and contains_objective(text) and contains_assessment(text) and contains_plan:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 这里的subjective and objective的keywords不确定是否OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97a1abe-af1d-4be8-8546-98c6dadabe96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:32.779435Z",
     "iopub.status.busy": "2024-09-19T02:46:32.779226Z",
     "iopub.status.idle": "2024-09-19T02:46:32.785339Z",
     "shell.execute_reply": "2024-09-19T02:46:32.784460Z",
     "shell.execute_reply.started": "2024-09-19T02:46:32.779416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 直接根据assessment and plan来分割，前面是s_and_o，后面是a_and_p\n",
    "def split_assessment_plan(text):\n",
    "    match = re.search(r'assessment and plan', text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        split_index = match.start()\n",
    "        s_and_o = text[:split_index].strip()\n",
    "        a_and_p = text[split_index:].strip()\n",
    "        return s_and_o, a_and_p\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b71afbe-cf56-470a-ba9d-022e8374b95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T02:46:32.787678Z",
     "iopub.status.busy": "2024-09-19T02:46:32.787375Z",
     "iopub.status.idle": "2024-09-19T02:46:39.816223Z",
     "shell.execute_reply": "2024-09-19T02:46:39.815466Z",
     "shell.execute_reply.started": "2024-09-19T02:46:32.787657Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# grouped by SUBJECT_ID\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m grouped \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject_id, group \u001b[38;5;129;01min\u001b[39;00m grouped:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# sorted by row_id\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     sorted_group \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROW_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "# grouped by SUBJECT_ID\n",
    "grouped = df.groupby('SUBJECT_ID')\n",
    "\n",
    "for subject_id, group in grouped:\n",
    "    # sorted by row_id\n",
    "    sorted_group = group.sort_values(by='ROW_ID', ascending=False)\n",
    "    \n",
    "    for index, row in sorted_group.iterrows():\n",
    "        if check_condition(row['TEXT']):\n",
    "            row_data = row.to_dict()\n",
    "            \n",
    "            s_and_o, a_and_p = split_assessment_plan(row['TEXT'])\n",
    "            \n",
    "            if s_and_o and a_and_p:\n",
    "                row_data['s_and_o'] = s_and_o\n",
    "                row_data['a_and_p'] = a_and_p\n",
    "                result_list.append(row_data)\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "print(len(result_list))\n",
    "\n",
    "# store into a json file\n",
    "with open('unique_notes.json', 'w') as json_file:\n",
    "    json.dump(result_list, json_file, indent=4)\n",
    "\n",
    "print(\"unique_notes.json is done\")\n",
    "\n",
    "# 先以subject_id分组，然后对其row_id进行从近到远排序，对应的就是降序；然后从上到下遍历，直到取到满足soap condition并且能分割assessment and plan的note\n",
    "# 这样结束之后有5074条满足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0423526-29d0-4ecc-be8a-f53749161d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719241\n",
      "99991\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"data/virtual_hospital/MIMIC_Modified.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "for note in reversed(data):\n",
    "    print(note['ROW_ID'])\n",
    "    print(note['SUBJECT_ID'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88639ec-73aa-4be2-a23a-dffea9756eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Chief_Complaint', 'HPI', 'Allergies', 'Past_Medical_History', 'Current_Medications', 'Vital_Signs', 'Physical_Examination_Findings', 'Family_History', 'Social_History', 'Review_of_Systems', 'Assessment', 'Plan'])\n",
      "Patient's Chief_Complaint: Consultation regarding evaluation and management of perioperative risk.,Patient's HPI: 50 y/o woman with hypertension, dyslipidemia, tobacco use, and peripheral artery disease who had recent left external iliac to above knee artery bypass and was admitted with bleeding at the site of an infected groin wound.,Patient's Allergies: Penicillin,Patient's Past_Medical_History: Hypertension, Dyslipidemia, Peripheral arterial disease with history of ischemic ulcerations in right lower extremity and disabling claudication in left lower extremity. Surgeries include right common iliac PTA, right common femoral endarterectomy/patch angioplasty, left femoral to right above knee artery bypass, and left external iliac to above knee artery bypass.,Patient's Current_Medications: Metoprolol 100 mg, HCTZ 25 mg, Simvastatin 40 mg, Lisinopril 10 mg, Plavix 75 mg, among IV medications including Metoprolol Tartrate, Acetaminophen, Morphine, Vancomycin, Ciprofloxacin, Nicotine Patch, Magnesium Sulfate, Potassium Chloride, and Metronidazole.,Patient's Vital_Signs: {'Temperature': '97.6 degrees Fahrenheit', 'Blood Pressure': '104/54 mmHg supine', 'Heart Rate': '84 bpm', 'Respiratory Rate': '14 bpm', 'O2 Saturation': '99% on RA'},Patient's Physical_Examination_Findings: {'General': 'Pleasant, well-appearing woman in no distress.', 'Cardiovascular': 'Normal rhythm, normal heart sounds, no murmurs, bandaged left groin with slight ooze of blood.', 'Respiratory': 'Clear to auscultation bilaterally, no wheezes.', 'Abdominal': 'Soft, non-tender, no enlargement of abdominal aorta.', 'Neurological': 'Alert and oriented, cranial nerves intact.'},Patient's Family_History: No early coronary artery disease or sudden cardiac death.,Patient's Social_History: Works as a secretary, positive tobacco use but has not smoked since surgery a month ago, consumes alcohol weekly, no illicit drug use.,Patient's Review_of_Systems: Negative for constitutional symptoms, respiratory issues, gastrointestinal symptoms, and neurological signs.,Patient's Assessment: 50 y/o female with multiple cardiovascular risk factors presenting for perioperative risk assessment prior to vascular surgery.,Patient's Plan: ,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from tools import patient_agent, doctor_agent\n",
    "import tqdm\n",
    "# loop over all the folders in data_virtual_hospital\n",
    "\n",
    "gpt4o = \"gpt-4o\"\n",
    "max_iter = 30\n",
    "self_critic = True\n",
    "\n",
    "\n",
    "def assistant(chat_history: str, patient_info: str):\n",
    "    \"\"\"\n",
    "        Tool that calls a chain to find the missing information,\n",
    "            valid parameter include \"chat_history\": chat_history, \"patient_info\": patient's background\n",
    "        \"\"\"\n",
    "    prompt = load_prompt(\"prompts/Virtual_hospital/Conversation_self_critic.yaml\")\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, verbose=False)\n",
    "    response = chain.invoke({\"chat_history\": chat_history, \"patient_info\": patient_info})\n",
    "    return response[\"text\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # root_dir = \"./data/virtual_hospital/MIMIC_Modified2\"\n",
    "    # list = os.listdir(root_dir)\n",
    "    \n",
    "    with open(\"data/virtual_hospital/MIMIC_Modified.json\", \"r\") as f:\n",
    "        notes = json.load(f) \n",
    "    assistant_ = StructuredTool.from_function(assistant)\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    for data in reversed(notes):\n",
    "        ROW_ID = data['ROW_ID']\n",
    "        SUBJECT_ID = data['SUBJECT_ID']\n",
    "        output_filename = f\"{SUBJECT_ID}_{ROW_ID}.txt\"\n",
    "        \n",
    "        if os.path.exists(f\"output/MIMIC/Conversation_0925/{output_filename}\"):\n",
    "            continue\n",
    "        # print(f\"{len(os.listdir('output/MIMIC/Conversation2'))}/{len(os.listdir(root_dir))}: {file}\")\n",
    "        # with open(f\"{root_dir}/{file}\") as json_file:\n",
    "        #     data = json.load(json_file)\n",
    "        #     json_file.close()\n",
    "\n",
    "        doctor_info = (f\"Patient's Age: {data['Doctor_Actor']['Age']},\"\n",
    "                       f\"Patient's Gender: {data['Doctor_Actor']['Gender']},\"\n",
    "                       f\"Reason for Visit: {data['Doctor_Actor']['Reason_for_visit']}\"\n",
    "                       f\"Physical Examination Findings: {data['Patient_Actor']['Physical_Examination_Findings']}\"\n",
    "                       f\"Vital Signs: {data['Patient_Actor']['Vital_Signs']}\"\n",
    "                       f\"Review of Systems: {data['Patient_Actor']['Review_of_Systems']} \"\n",
    "                       )\n",
    "        patient_info = \"\"\n",
    "        print(data['Patient_Actor'].keys())\n",
    "        # for key in data['Patient_Actor'].keys():\n",
    "        patient_info = \"\".join(f\"Patient's {key}: {data['Patient_Actor'][key]},\" for key in data['Patient_Actor'].keys())\n",
    "        print(patient_info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07becacb-42cc-435f-8f37-ee89bc947b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"data/virtual_hospital/MIMIC_Modified.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "with open(\"data/virtual_hospital/physician.csv\", 'r') as f:\n",
    "    physician_notes = pd.read_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb308595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5070\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data_update = []\n",
    "for note in data:\n",
    "    ROW_ID = int(note['ROW_ID'])\n",
    "    SUBJECT_ID = note['SUBJECT_ID']\n",
    "    original_note = physician_notes[physician_notes[\"ROW_ID\"] == ROW_ID]\n",
    "    # print(type(original_note['TEXT'].iloc[0]))\n",
    "    \n",
    "    s_and_o, a_and_p = split_assessment_plan(original_note['TEXT'].iloc[0])\n",
    "            \n",
    "    if s_and_o and a_and_p:\n",
    "        note['s_and_o'] = s_and_o\n",
    "        note['a_and_p'] = a_and_p\n",
    "    data_update.append(note)\n",
    "print(len(data_update))\n",
    "with open(\"data/MIMIC_update.jsons\", \"w\") as f:\n",
    "    json.dump(data_update, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd925764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5070\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/MIMIC_update.jsons\", 'r') as f:\n",
    "    notes_update = json.load(f)\n",
    "counter = 0\n",
    "for note in notes_update:\n",
    "    counter+=1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58056e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 5070/5070 [16:49<00:00,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame with columns 'prompts' and 'completion'\n",
    "df = pd.DataFrame(columns=['instruction', 'output', 'input'])\n",
    "\n",
    "with open(f\"data/virtual_hospital/MIMIC_update_1007.json\", 'r') as f:\n",
    "    physician_notes = json.load(f)\n",
    "\n",
    "with open(\"data_process/SFT_dataset_utils/InfoGatherQA_instruction.txt\", 'r') as f:\n",
    "    instruction_template = f.read()\n",
    "# print(instruction)\n",
    "# instruction = instruction_template.replace(\"<info>\", \"Patient's information\").replace(\"<chat_history>\", \"How's your feeling?\")\n",
    "# print(instruction)\n",
    "\n",
    "for filename in tqdm(os.listdir(\"data/virtual_hospital/conversation\"), desc=\"Processing files\"):\n",
    "    \n",
    "    # get the conversation data\n",
    "    with open(f\"data/virtual_hospital/conversation/{filename}\", 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        conversation = f.read()\n",
    "\n",
    "    # get patient's information\n",
    "    filename = filename[:-4]\n",
    "    ROW_ID = filename.split(\"_\")[1]\n",
    "    SUBJECT_ID = filename.split(\"_\")[0]\n",
    "    id = f\"{SUBJECT_ID}_{ROW_ID}\"\n",
    "\n",
    "    patient_info = str(physician_notes[id]['Doctor_Actor'])\n",
    "    instruction_template = instruction_template.replace(\"<info>\", patient_info)\n",
    "    iterations = conversation.split(\"\\n\")\n",
    "   \n",
    "\n",
    "    conversations = \"\"\n",
    "    # print(len(iterations))\n",
    "    for i in range(0, len(iterations), 2):\n",
    "        # instruction = instruction_template.replace(\"<chat_history>\", conversations)\n",
    "\n",
    "        if \"Doctor\" in iterations[i]:\n",
    "            output = iterations[i]\n",
    "            new_row = pd.DataFrame([[instruction_template, output.replace(\"Doctor: \", \"\"), conversations]], columns=['instruction', 'output', 'input'])\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "        else: \n",
    "            # print(f\"break at {i} th iteration Due to missing doctor\")\n",
    "            # print(iterations[i])\n",
    "\n",
    "            break\n",
    "        \n",
    "        if i+1 < len(iterations)-1 and \"Doctor\" in iterations[i] and \"Patient\" in iterations[i+1]:\n",
    "            conversations += f\"{iterations[i]}\\n\"\n",
    "            conversations += f\"{iterations[i+1]}\\n\"\n",
    "        else:\n",
    "            # print(f\"break at {i} th iteration\")\n",
    "            break\n",
    "df.to_csv('data/SFT_dataset/conversation.csv')\n",
    "    # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6fd835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n",
      "Index(['instruction', 'output', 'input'], dtype='object')\n",
      "Doctor: When did you first notice the changes in your mental status?\n",
      "Patient: I first noticed the changes in my mental status about a few days ago. It started with feeling more confused and disoriented than usual.\n",
      "\n",
      "Can you describe how your confusion and disorientation have changed over the past few days?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_1 = pd.read_csv('data/SFT_dataset/conversation_lite.csv', index_col=0)\n",
    "print(data_1.shape)\n",
    "print(data_1.columns)\n",
    "print(data_1['input'][1])\n",
    "print(data_1['output'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28d5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"data/SFT_dataset/llama_assessment.json\", 'r') as f:\n",
    "    assessments = json.load(f)\n",
    "with open(\"data/SFT_dataset/llama_plan1.json\", \"r\") as f:\n",
    "    plan1  = json.load(f)\n",
    "with open(\"data/SFT_dataset/llama_plan2.json\", \"r\") as f:\n",
    "    plan2 = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac97d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "assessments_df = pd.DataFrame(assessments)\n",
    "plan1_df = pd.DataFrame(plan1)\n",
    "plan2_df = pd.DataFrame(plan2)\n",
    "conversation_df = pd.read_csv(\"data/SFT_dataset/conversation.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff947dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152078, 3)\n",
      "(5070, 3)\n",
      "(4755, 3)\n",
      "(4755, 3)\n"
     ]
    }
   ],
   "source": [
    "print(conversation_df.shape)\n",
    "print(assessments_df.shape)\n",
    "print(plan1_df.shape)\n",
    "print(plan2_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7496af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_train = conversation_df[: 5000]\n",
    "assessments_train = assessments_df[: 4000]\n",
    "plan1_train = plan1_df[: 4000]\n",
    "plan2_train = plan2_df[: 4000]\n",
    "train = pd.concat([conversation_train, assessments_train, plan1_train, plan2_train], axis=0)\n",
    "train.to_csv(\"data/SFT_dataset/train_01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b923f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instruction', 'output', 'input'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c76a9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_val = conversation_df[150000: 151000]\n",
    "assessments_val = assessments_df[4000: 4500]\n",
    "plan1_val = plan1_df[4000: 4400]\n",
    "plan2_val = plan2_df[4000: 4400]\n",
    "val = pd.concat([conversation_val, assessments_val, plan1_val, plan2_val], axis=0)\n",
    "val.to_csv(\"data/SFT_dataset/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b9b3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_test = conversation_df[151000:]\n",
    "assessments_test = assessments_df[4500:]\n",
    "plan1_test = plan1_df[4400:]\n",
    "plan2_test = plan2_df[4400:]\n",
    "test = pd.concat([conversation_test, assessments_test, plan1_test, plan2_test], axis=0)\n",
    "test.to_csv(\"data/SFT_dataset/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d96323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27240, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "# print(val.shape)\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d84a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "with open(f\"data/virtual_hospital/MIMIC_update.json\", 'r') as f:\n",
    "    physician_notes = json.load(f)\n",
    "\n",
    "print(type(physician_notes))\n",
    "physician_notes_new = {}\n",
    "for note in physician_notes:\n",
    "    id = f\"{note['SUBJECT_ID']}_{note['ROW_ID']}\"\n",
    "    physician_notes_new[id] = note\n",
    "with open(f\"data/virtual_hospital/MIMIC_update_1007.json\", \"w\") as f:\n",
    "    json.dump(physician_notes_new, f, indent=4)\n",
    "print(type(physician_notes_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43598e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'Age': '25', 'Gender': 'Female', 'Reason_for_visit': 'Dyspnea and weakness'}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open(f\"data/virtual_hospital/MIMIC_update_1007.json\", 'r') as f:\n",
    "    physician_notes = json.load(f)\n",
    "print(type(physician_notes))\n",
    "print(str(physician_notes['109_385223']['Doctor_Actor']))\n",
    "patient_info = str(physician_notes['109_385223']['Doctor_Actor'])\n",
    "print(type(patient_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b199ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading data from MIMIC IV\n",
    "import pandas as pd\n",
    "\n",
    "discharge = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\discharge.csv\")\n",
    "discharge_detail = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\discharge_detail.csv\")\n",
    "# radiology_detail = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\radiology_detail.csv\")\n",
    "# radiology = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\radiology.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d36d7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['note_id', 'subject_id', 'hadm_id', 'note_type', 'note_seq',\n",
      "       'charttime', 'storetime', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(discharge.columns)\n",
    "discharge.iloc[0]\n",
    "with open(\"C:/Projects/VirtualHospital/data/MIMIC_IV/discharge0.txt\", 'w') as f:\n",
    "    f.write(discharge.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a9da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['note_id', 'subject_id', 'field_name', 'field_value', 'field_ordinal'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "note_id          10000032-DS-22\n",
       "subject_id             10000032\n",
       "field_name               author\n",
       "field_value                 ___\n",
       "field_ordinal                 1\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(discharge_detail.columns)\n",
    "discharge_detail.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f19b66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading data from MIMIC IV\n",
    "import pandas as pd\n",
    "\n",
    "# discharge = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\discharge.csv\")\n",
    "# discharge_detail = pd.read_csv(\"C:\\Projects\\VirtualHospital\\data\\MIMIC_IV\\discharge_detail.csv\")\n",
    "# radiology_detail = pd.read_csv(\"C:/Projects/VirtualHospital/data/MIMIC_IV/radiology_detail.csv\")\n",
    "admissions = pd.read_csv(\"C:/Projects/VirtualHospital/data/MIMIC_IV/admissions.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a62ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime',\n",
      "       'admission_type', 'admit_provider_id', 'admission_location',\n",
      "       'discharge_location', 'insurance', 'language', 'marital_status', 'race',\n",
      "       'edregtime', 'edouttime', 'hospital_expire_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(admissions.columns)\n",
    "# admissions.iloc[0]['text']\n",
    "output = \"\"\n",
    "for key in admissions.columns:\n",
    "    output += f\"{key}: {admissions.iloc[0][key]}\\n\\n\"\n",
    "with open(\"C:/Projects/VirtualHospital/data/MIMIC_IV/admissions.txt\", 'w') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d09e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualHospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
