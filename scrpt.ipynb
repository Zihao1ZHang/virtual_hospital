{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name = \"data/virtual_hospital/orginal_VP_data/physician.csv\"\n",
    "data = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_subjective(text):\n",
    "    subjective_keywords = [\"reports\", \"complains\", \"symptoms\", \"history of\"]\n",
    "    return any(keyword in text.lower() for keyword in subjective_keywords)\n",
    "\n",
    "def contains_objective(text):\n",
    "    objective_keywords = [\"vital signs\", \"physical examination\", \"labs\", \"imaging\", \"findings\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_assessment(text):\n",
    "    objective_keywords = [\"assessment\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def contains_plan(text):\n",
    "    objective_keywords = [\"plan\"]\n",
    "    return any(keyword in text.lower() for keyword in objective_keywords)\n",
    "\n",
    "def check_condition(text):\n",
    "    if contains_subjective(text) and contains_objective(text):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接根据assessment and plan来分割，前面是s_and_o，后面是a_and_p\n",
    "def split_assessment_plan(text):\n",
    "    match = re.search(r'assessment and plan', text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        split_index = match.start()\n",
    "        s_and_o = text[:split_index].strip()\n",
    "        a_and_p = text[split_index:].strip()\n",
    "        return s_and_o, a_and_p\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5074\n",
      "unique_notes.json is done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "result_list = []\n",
    "\n",
    "# grouped by SUBJECT_ID\n",
    "grouped = data.groupby('SUBJECT_ID')\n",
    "counter = 0\n",
    "for subject_id, group in grouped:\n",
    "    # sorted by row_id\n",
    "    sorted_group = group.sort_values(by='ROW_ID', ascending=False)\n",
    "    \n",
    "    for index, row in sorted_group.iterrows():\n",
    "        if check_condition(row['TEXT']):\n",
    "            row_data = row.to_dict()\n",
    "            \n",
    "        \n",
    "            s_and_o, a_and_p = split_assessment_plan(row['TEXT'])\n",
    "            \n",
    "            if s_and_o and a_and_p:\n",
    "                row_data['s_and_o'] = s_and_o\n",
    "                row_data['a_and_p'] = a_and_p\n",
    "                result_list.append(row_data)\n",
    "                counter += 1\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "print(counter)\n",
    "\n",
    "with open('data/virtual_hospital/MIMIC_unique_notes.json', 'w') as json_file:\n",
    "    json.dump(result_list, json_file, indent=4)\n",
    "\n",
    "print(\"unique_notes.json is done\")\n",
    "# print(len(result_list))\n",
    "\n",
    "# # store into a json file\n",
    "# with open('unique_notes.json', 'w') as json_file:\n",
    "#     json.dump(result_list, json_file, indent=4)\n",
    "\n",
    "# print(\"unique_notes.json is done\")\n",
    "\n",
    "# 先以subject_id分组，然后对其row_id进行从近到远排序，对应的就是降序；然后从上到下遍历，直到取到满足soap condition并且能分割assessment and plan的note\n",
    "# 这样结束之后有5074条满足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'CHARTTIME', 'STORETIME', 'CATEGORY', 'DESCRIPTION', 'CGID', 'ISERROR', 'TEXT', 's_and_o', 'a_and_p'])\n",
      "109\n",
      "385223\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"data/virtual_hospital/MIMIC_unique_notes.json\", \"r\") as f:\n",
    "    physician_note = json.load(f)\n",
    "for v in physician_note:\n",
    "    print(v.keys())\n",
    "    print(v['SUBJECT_ID'])\n",
    "    print(v['ROW_ID'])\n",
    "    break\n",
    "# print(physician_note)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VirtualHospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
